{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObeyRNqt3ACGAcqP2jQ7A3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyy2005/Classification-/blob/main/Fashion_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Studi Kasus Klasifikasi Gambar Fashion**\n",
        "\n",
        "___\n",
        "\n",
        "![gambar](https://assets.cdn.dicoding.com/original/academy/dos-5aa5f3cf8647dd9db97e85145ccb6c0e20240106160007.jpeg)\n",
        "\n",
        "____"
      ],
      "metadata": {
        "id": "cnyPHcZX-FEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "gYG2QUUfgtU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "data_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = data_mnist.load_data()"
      ],
      "metadata": {
        "id": "sEet9_hsg5aL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dalam klasifikasi gambar, setiap piksel pada gambar memiliki nilai dari 0 sampai 255. Kita perlu melakukan normalisasi dengan membagi setiap pixel pada gambar dengan 255. Dengan nilai yang telah dinormalisasi, jaringan saraf dapat belajar dengan lebih baik."
      ],
      "metadata": {
        "id": "l4ZiZ30qhE4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "xqw1nA1uhLVt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada langkah berikutnya, kita mendefinisikan arsitektur dari jaringan saraf yang akan kita latih."
      ],
      "metadata": {
        "id": "JH-Iq0r4hRO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(256,activation=tf.nn.relu), # Menambahkan hidden layer kedua\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "bEITeEtvhXWE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pada kode di atas, ketiga layer tersebut terdiri dari input layer, hidden layer, dan output layer.\n",
        "\n",
        "Untuk membuat sebuah model di Keras, kita bisa memanggil fungsi\n",
        " ```\n",
        "tf.keras.models.Sequential([...])\n",
        "```\n",
        "dan menampungnya pada sebuah variabel. Model sequential pada Keras adalah tumpukan layer-layer yang melakukan proses perhitungan sehingga mendapatkan output yang sesuai dengan tugasnya.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mIwmzUgZhvAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definisi dari 3 layer utama pada model sequential.\n",
        "\n",
        "* **Input layer**\n",
        "\n",
        "> Layer yang memiliki parameter ‘input_shape’. **input_shape** sendiri adalah resolusi dari gambar-gambar pada data latih. Dalam hal ini, sebuah ***gambar MNIST memiliki resolusi 28x28 pixel*** sehingga input shape-nya adalah **(28, 28)**. Sebuah layer **Flatten** pada Keras akan berfungsi untuk meratakan input. Meratakan di sini artinya mengubah gambar yang merupakan **matriks 2 dimensi menjadi array 1 dimensi.** Pada kasus kita, sebuah gambar MNIST yang merupakan matriks **28x28 elemen**, akan diubah menjadi larik/array satu dimensi sebesar **784 elemen**.\n",
        "\n",
        "* **Hidden layer**\n",
        "\n",
        "> **Dense** layer pada Keras merupakan layer yang dapat dipakai sebagai hidden layer dan output layer pada sebuah **MLP** *(Multilayer Perceptron)*. Parameter unit merupakan jumlah perceptron pada sebuah layer. Kita dapat menggunakan fungsi aktivasi **relu** *(rectified linear unit)* atau fungsi aktivasi lain untuk hidden layer kita.\n",
        "\n",
        "* **Ouput layer**\n",
        "\n",
        "> Output layer didefinisikan dengan membuat sebuah dense layer. Jumlah unit menyesuaikan dengan jumlah label pada dataset. Untuk fungsi aktivasi pada layer output, gunakan fungsi aktivasi **sigmoid** ketika hanya terdapat ***2 kelas/label*** pada dataset. Untuk dataset yang memiliki ***3 kelas atau lebih***, gunakan fungsi aktivasi **softmax**. Fungsi aktivasi softmax akan memilih kelas mana yang memiliki **probabilitas tertinggi**. Untuk data fashion MNIST, kita akan menggunakan fungsi aktivasi softmax karena terdapat **10 kelas.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cNS2Y5_Vibd-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proses pembelajaran Machine Learning\n",
        "\n",
        "___\n",
        "![gambar](https://assets.cdn.dicoding.com/original/academy/dos-04483baacfc9e2d35b7989acb1542daa20240106160003.jpeg)\n",
        "\n",
        "\n",
        "> Gambar di atas menunjukkan jumlah layer yang direpresentasikan oleh neuron.Setiap neuron yang terhubung mewakili perhitungan dari sebuah **perceptron**. Proses pembelajaran ini terdiri dari 5 komponen, yaitu bobot atau **weights (Wi)** dan **bias (W0**), penjumlahan atau **sum (∑)**, fungsi aktivasi atau non **linearity function (⎰)**, dan **output (ŷ)**.\n",
        "\n",
        "\n",
        "## Fungsi matematis\n",
        "\n",
        "![gambar](https://assets.cdn.dicoding.com/original/academy/dos-0d232dc01e0891112f295f0cc35127a320240106160002.jpeg)\n",
        "\n",
        "\n",
        "* ŷ = output/keluaran\n",
        "* w0 = bias\n",
        "* w1 = weight/bobot\n",
        "* x1 = input\n",
        "* g = fungsi aktivasi\n",
        "\n",
        "> dapat disimpulkan bahwa output/keluaran **(ŷ)** merupakan hasil perhitungan dari bias **(w0)** ditambah dengan total dari input **(x1)** dikalikan dengan bobot **(w1)**. Kemudian, nilai akhir dari perhitungan tersebut dikalikan dengan fungsi aktivasi **(g)** sehingga mendapatkan sebuah nilai **output/keluaran.**\n"
      ],
      "metadata": {
        "id": "FEEMsFtdox1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Fungsi aktivasi (g) pada perceptron bertugas untuk membuat jaringan saraf mampu menyesuaikan pola pada data non linier.\n",
        "**Tanpa fungsi aktivasi**, jaringan saraf hanya bisa mengenali pola linier seperti garis pada regresi linier. Hasilnya seperti gambar ke 2.\n",
        "\n",
        "![gambar](https://assets.cdn.dicoding.com/original/academy/dos-df4e37db7a676e6931515297f94d2ba520240106160002.jpeg) ![gambar](https://assets.cdn.dicoding.com/original/academy/dos-af627850c6b8127c402f0d033ab67c4b20240106155956.jpeg)\n",
        "\n",
        "\n",
        "Fungsi aktivasi (g) itulah yang memungkinkan jaringan saraf dapat mengenali pola non-linier tanpa memperhatikan kompleksitas atau sebaran data yang ada. Penggunaan fungsi aktivasi (g) akan menghasilkan batasan sebaran data sebagai berikut.\n",
        "\n",
        "![gambar](https://assets.cdn.dicoding.com/original/academy/dos-5ba489f0826271c9baae9a4b2f75807120240106160002.jpeg)"
      ],
      "metadata": {
        "id": "UvVVix6TsInb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah membuat arsitektur machine learning, model kita belum bisa melakukan apa pun. Agar model bisa belajar, kita perlu memanggil fungsi **compile** pada model dan menspesifikasikan **optimizer** dan **loss function**. Dua hal ini memiliki peran yang sangat penting ketika kita membangun *model* machine learning. **Loss function** berfungsi untuk menghitung perbedaan antara output prediksi dengan output sesungguhnya, sedangkan **optimizer** berfungsi untuk menyesuaikan nilai parameter sehingga dapat meminimalisir kesalahan pada saat pembelajaran dilakukan.\n",
        "\n",
        "\n",
        "Salah satu **optimizer** yang biasa digunakan adalah **Adam**. Untuk ***loss function***, kita dapat menggunakan **sparse categorical entropy** pada kasus klasifikasi *3 kelas atau lebih*; sedangkan pada masalah *2 kelas*, loss function yang lebih tepat adalah **binary cross entropy**. Parameter **metrics** berfungsi untuk menampilkan metrik yang dipilih pada proses **pelatihan model**."
      ],
      "metadata": {
        "id": "w_vgUJl7v9ML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Fz0Nql65xFKi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah membuat **arsitektur MLP** dan menentukan **optimizer** serta **loss function**, kita dapat melatih model pada data training. Parameter **epoch** merupakan jumlah berapa kali sebuah model melakukan propagasi balik."
      ],
      "metadata": {
        "id": "IhcR2Mc7xI9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meningkatkan jumlah epochs menjadi 15 untuk memberi model lebih banyak waktu belajar\n",
        "model.fit(x_train,y_train,epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8p3LtZOxTuj",
        "outputId": "7864b16e-8115-4272-e135-b7ec47fe1c1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.1752\n",
            "Epoch 2/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9377 - loss: 0.1629\n",
            "Epoch 3/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1602\n",
            "Epoch 4/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9388 - loss: 0.1570\n",
            "Epoch 5/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9417 - loss: 0.1501\n",
            "Epoch 6/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.1472\n",
            "Epoch 7/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9454 - loss: 0.1396\n",
            "Epoch 8/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9451 - loss: 0.1395\n",
            "Epoch 9/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9490 - loss: 0.1320\n",
            "Epoch 10/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.1340\n",
            "Epoch 11/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9514 - loss: 0.1259\n",
            "Epoch 12/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9495 - loss: 0.1258\n",
            "Epoch 13/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.1182\n",
            "Epoch 14/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9542 - loss: 0.1160\n",
            "Epoch 15/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9558 - loss: 0.1146\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x794fb45dab40>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}